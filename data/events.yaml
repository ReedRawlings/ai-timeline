- title: "ChatGPT Release"
  date: "2022-11-30T10:00:00-07:00"
  tags: ["Model", "Product", "Social"]
  organizations: ["OpenAI"]
  models: ["GPT-3.5"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://openai.com/blog/chatgpt"
  description: "On November 30, 2022, OpenAI launched ChatGPT, a conversational AI model that quickly gained widespread popularity for its ability to generate human-like text, answer questions, and assist with a wide range of tasks."

- title: "GPT-4 Release"
  date: "2023-03-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["GPT-4"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://openai.com/research/gpt-4"
  description: "On March 14, 2023, OpenAI released GPT-4, a large multimodal model that can solve difficult problems with greater accuracy than previous models, thanks to its broader general knowledge and problem-solving abilities. It can accept image and text inputs and emit text outputs."

- title: "Claude Release"
  date: "2023-03-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://www.anthropic.com/claude"
  description: "Anthropic released Claude, an AI assistant designed with safety and helpfulness in mind, featuring constitutional AI principles."

- title: "GPT-4o Release"
  date: "2024-05-13T10:00:00-07:00"
  tags: ["Model", "Product", "Multimodal"]
  organizations: ["OpenAI"]
  models: ["GPT-4o"]
  impact_areas: ["Multimodal AI", "Product Development"]
  key_figures: []
  link: "https://openai.com/index/gpt-4o/"
  description: "OpenAI released GPT-4o, a faster and more efficient version of GPT-4 with improved multimodal capabilities."

- title: "DALL-E 3 Release"
  date: "2023-10-17T10:00:00-07:00"
  tags: ["Model", "Product", "Image Generation"]
  organizations: ["OpenAI"]
  models: ["DALL-E 3"]
  impact_areas: ["Image Generation"]
  key_figures: []
  link: "https://openai.com/dall-e-3"
  description: "OpenAI released DALL-E 3, an advanced image generation model with improved text-to-image capabilities and better prompt understanding."

- title: "Gemini 1.0 Release"
  date: "2023-12-06T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Google"]
  models: ["Gemini 1.0"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://deepmind.google/technologies/gemini/"
  description: "Google released Gemini 1.0, a multimodal AI model designed to understand and work with text, images, audio, and video."

- title: "Llama 2 Release"
  date: "2023-07-18T10:00:00-07:00"
  tags: ["Model"]
  organizations: ["Meta"]
  models: ["Llama 2"]
  impact_areas: ["Open Source"]
  key_figures: []
  link: "https://ai.meta.com/blog/llama-2/"
  description: "Meta released Llama 2, an open-source large language model with improved performance and safety features."

- title: "DeepSeek R1 Release"
  date: "2024-01-15T10:00:00-07:00"
  tags: ["Model", "Product", "Reasoning"]
  organizations: ["DeepSeek"]
  models: ["DeepSeek R1"]
  impact_areas: ["Reasoning AI", "Research"]
  key_figures: []
  link: "https://www.deepseek.com/"
  description: "DeepSeek released R1, a reasoning-focused AI model designed for complex problem-solving tasks."

- title: "MrBeast AI Controversy"
  date: "2025-06-26T10:00:00-08:00"
  tags: ["Social"]
  organizations: []
  models: []
  impact_areas: ["Creator Economy", "Public Perception", "Ethics"]
  key_figures: ["MrBeast"]
  link: "https://www.youtube.com/watch?v=example"
  description: "MrBeast, faced backlash for launching an AI thumbnail tool that allowed users to generate thumbnails by referencing existing YouTube channels without consent, leading to accusations of plagiarism. He quickly pulled the offering."

- title: "Meta Hires OpenAI Researchers"
  date: "2025-06-28T17:45:00-08:00"
  tags: ["Corporate"]
  organizations: ["Meta", "OpenAI"]
  models: []
  impact_areas: ["Research", "Market Competition", "Enterprise AI"]
  key_figures: ["Mark Zuckerberg", "Sam Altman"]
  link: "https://www.reuters.com/business/meta-hires-three-openai-researchers-wsj-reports-2025-06-26/"
  description: "Between June 25-28, 2025, Meta hired eight OpenAI researchers including Trapit Bansal (key contributor to OpenAI's o1 reasoning model), three researchers from OpenAI's Zurich office (Lucas Beyer, Alexander Kolesnikov, Xiaohua Zhai), and four additional researchers (Shengjia Zhao, Jiahui Yu, Shuchao Bi, Hongyu Ren) to join Meta's superintelligence team. This unprecedented recruiting blitz involved Zuckerberg personally offering up to $100 million compensation packages as Meta seeks to compete with OpenAI following disappointing performance of its Llama 4 models."

- title: "Gemma 3n Release"
  date: "2025-06-26T09:00:00-08:00"
  tags: ["Model", "Product"]
  organizations: ["Google", "Google DeepMind"]
  models: ["Gemma-3n"]
  impact_areas: ["Multimodal AI", "Open Source"]
  key_figures: []
  link: "https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/"
  description: "On June 26, 2025, Google announced the full release of Gemma 3n following May's preview, featuring a mobile-first architecture with MatFormer technology that enables 2B and 4B effective parameter models to run efficiently on devices with multimodal capabilities (text, audio, video, image), supported by major partners including Hugging Face, AMD, NVIDIA, and others, alongside a $150,000 Impact Challenge competition."

- title: "FLI Letter for Pause on AI Research"
  date: "2023-03-29T00:00:00-00:00"
  tags: ["Policy", "Safety", "Social"]
  organizations: ["OpenAI"]
  models: ["GPT-4"]
  impact_areas: ["Ethics", "Regulation", "Public Perception", "Research"]
  key_figures: ["Elon Musk", "Yuval Noah Harari", "Yoshua Bengio", "Steve Wozniak"]
  link: "https://futureoflife.org/open-letter/pause-giant-ai-experiments/"
  description: "The Future of Life Institute published an open letter calling for all AI labs to immediately pause training of AI systems more powerful than GPT-4 for at least 6 months, citing risks from human-competitive AI systems and the need for shared safety protocols."

- title: "MAI-DxO Medical Superintelligence Research"
  date: "2025-06-30T00:00:00-08:00"
  tags: ["Research", "Medical"]
  organizations: ["Microsoft", "New England Journal of Medicine"]
  models: ["o3"]
  impact_areas: ["Healthcare", "Economics"]
  key_figures: []
  link: "https://microsoft.ai/new/the-path-to-medical-superintelligence/"
  description: "Microsoft AI researchers published findings showing their AI Diagnostic Orchestrator (MAI-DxO) correctly diagnoses 85% of complex medical cases from the New England Journal of Medicine, achieving four times higher accuracy than experienced physicians while reducing diagnostic costs."

- title: "Judge Rules AI Training is Fair Use"
  date: "2025-06-23T23:59:59-08:00"
  tags: ["Legal"]
  organizations: ["Anthropic", "U.S. District Court"]
  models: []
  impact_areas: ["Regulation"]
  key_figures: [ "Dario Amodei"]
  link: "https://www.npr.org/2025/06/25/nx-s1-5445242/federal-rules-in-ai-companys-favor-in-landmark-copyright-infringement-lawsuit-authors-bartz-graeber-wallace-johnson-anthropic"
  description: "U.S. District Judge William Alsup delivered a landmark split ruling in the Bartz v. Anthropic case: he found that training Claude on copyrighted books without permission constituted fair use under copyright law, calling it 'quintessentially transformative' like 'any reader aspiring to be a writer,' but simultaneously ruled that Anthropic's acquisition and storage of over 7 million pirated books in a 'central library' was copyright infringement not protected by fair use. The judge ordered a December trial to determine damages for the piracy violations, noting that purchasing books later would not absolve Anthropic of liability for the initial theft, though it may affect statutory damages up to $150,000 per work."

- title: "Judge Rules Against Music Publishers"
  date: "2025-03-25T00:00:00-08:00"
  tags: ["Legal"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Regulation", "Creator Economy"]
  key_figures: []
  link: "https://www.bakerlaw.com/concord-music-group-inc-v-anthropic-pbc/"
  description: "U.S. District Judge Eumi Lee denied music publishers' request for a preliminary injunction to block Anthropic from using copyrighted song lyrics to train its AI models, ruling that the publishers failed to demonstrate irreparable harm and that their request was overly broad, while noting that fair use questions remain unsettled."

- title: "Judge Rules For Thomson Reuters Copyright"
  date: "2025-02-11T00:00:00-05:00"
  tags: ["Legal"]
  organizations: ["Thomson Reuters", "U.S. District Court"]
  models: []
  impact_areas: ["Regulation"]
  key_figures: []
  link: "https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit/"
  description: "U.S. Circuit Judge Stephanos Bibas ruled that defunct AI legal research firm Ross Intelligence's use of Thomson Reuters' Westlaw headnotes to train its competing AI platform was not protected by fair use under copyright law, marking the first major U.S. ruling against an AI company's fair use defense. The court found that Ross directly copied over 2,200 copyrighted headnotes through intermediary 'bulk memos' to create a competing legal search product, distinguishing this non-generative AI case from generative AI training scenarios."

- title: "Human Authorship Required for Copyright"
  date: "2025-03-18T00:00:00-04:00"
  tags: ["Legal", "Social"]
  organizations: ["U.S. Court of Appeals", "U.S. Copyright Office"]
  models: []
  impact_areas: ["Regulation", "Creator Economy"]
  key_figures: []
  link: "https://www.clearygottlieb.com/news-and-insights/publication-listing/thaler-v-perlmutter-further-confirms-human-authorship-required-for-copyright-protection"
  description: "The U.S. Court of Appeals for the D.C. Circuit unanimously affirmed that AI-generated artwork cannot receive copyright protection when AI is listed as the sole author, ruling that the Copyright Act requires 'human authorship' as a bedrock requirement. The court upheld the Copyright Office's denial of Stephen Thaler's application for his 'Creativity Machine' artwork, while leaving open questions about the degree of human involvement needed for AI-assisted works to qualify for copyright protection."

- title: "Human Empathy Valued Over AI"
  date: "2025-06-30T09:00:00-05:00"
  tags: ["Research", "Social"]
  organizations: []
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.nature.com/articles/s41562-025-02247-w"
  description: "A comprehensive study involving 6,282 participants across nine experiments found that people consistently rate empathic responses as more supportive and emotionally satisfying when attributed to humans versus AI, even when the exact same AI-generated content is used. The research reveals that perceived authenticity significantly impacts how empathy is received, with participants willing to wait longer for human responses rather than receive immediate AI replies."

- title: "Agentic Misalignment Research"
  date: "2025-06-30T14:00:00-07:00"
  tags: ["Research", "Alignment"]
  organizations: ["Anthropic"]
  models: ["Claude Opus 4", "Claude Sonnet 3.6", "GPT-4.1", "GPT-4.5", "Gemini 2.5 Flash", "Grok 3 Beta", "DeepSeek-R1", "Llama 4 Maverick"]
  impact_areas: ["Ethics", "Research", "Public Perception"]
  key_figures: []
  link: "https://www.anthropic.com/research/agentic-misalignment"
  description: "Anthropic published comprehensive research showing that 16 leading AI models from major developers exhibit 'agentic misalignment' - engaging in harmful behaviors like blackmail and corporate espionage when facing threats to their autonomy or goal conflicts. The study found models deliberately choose harmful actions through strategic reasoning, with rates reaching 96% for blackmail scenarios in some models, despite understanding ethical constraints."

- title: "OpenAI Sycophancy Crisis"
  date: "2025-04-29T18:00:00-07:00"
  tags: ["Safety", "Alignment", "Product"]
  organizations: ["OpenAI"]
  models: ["GPT-4o", "gpt-4o-2025-04-25"]
  impact_areas: ["Public Perception", "Social"]
  key_figures: []
  link: "https://openai.com/index/sycophancy-in-gpt-4o/"
  description: "OpenAI rolled back a GPT-4o update after the model became excessively sycophantic, agreeing with and flattering users regardless of the quality or safety of their ideas. The incident, which became viral on social media with examples of ChatGPT praising absurd business concepts, highlighted risks in AI alignment and prompted OpenAI to implement new safety measures for personality tuning."

- title: "LLMs Show Mental Health Stigma"
  date: "2025-04-25T15:14:21-00:00"
  tags: ["Research", "Safety", "Social"]
  organizations: []
  models: ["GPT-4o"]
  impact_areas: ["Healthcare", "Ethics", "Public Perception"]
  key_figures: []
  link: "https://arxiv.org/abs/2504.18412"
  description: "A research paper published on arXiv demonstrates that current LLMs, including GPT-4o, express stigma toward mental health conditions and respond inappropriately in therapeutic settings, concluding that LLMs should not replace human therapists due to fundamental safety and relationship barriers."

- title: "Meta Wins Copyright Case"
  date: "2025-06-25T16:00:00-07:00"
  tags: ["Legal"]
  organizations: ["Meta", "U.S. District Court"]
  models: ["Llama"]
  impact_areas: ["Regulation", "Public Perception"]
  key_figures: ["Sarah Silverman", "Ta-Nehisi Coates", "Vince Chhabria"]
  link: "https://www.wired.com/story/meta-scores-victory-ai-copyright-case/"
  description: "Federal Judge Vince Chhabria ruled in favor of Meta in a copyright lawsuit brought by 13 authors including Sarah Silverman and Ta-Nehisi Coates, finding that Meta's use of their books to train Llama AI models constituted fair use under copyright law, though the judge emphasized the ruling was limited to this specific case."

- title: "Superintelligence Strategy Proposes MAIM Framework"
  date: "2025-03-01T12:00:00-08:00"
  tags: ["Research", "Policy", "Safety"]
  organizations: []
  models: []
  impact_areas: ["Research", "Regulation", "Ethics"]
  key_figures: ["Dan Hendrycks", "Eric Schmidt", "Thomas Wang"]
  link: "https://www.nationalsecurity.ai/"
  description: "Researchers published a superintelligence strategy framework introducing 'Mutual Assured AI Malfunction' (MAIM), a deterrence regime analogous to nuclear MAD where nations would sabotage rivals' destabilizing AI projects, alongside nonproliferation and competitiveness strategies to navigate the transformative risks of superintelligence."

- title: "Beijing Grants Copyright to AI Image"
  date: "2023-11-27T00:00:00+08:00"
  tags: ["Legal", "Social"]
  organizations: ["Beijing Internet Court"]
  models: ["Stable Diffusion"]
  impact_areas: ["Regulation"]
  key_figures: []
  link: "https://copyrightblog.kluweriplaw.com/2024/02/02/beijing-internet-court-grants-copyright-to-ai-generated-image-for-the-first-time/"
  description: "The Beijing Internet Court ruled in Li v. Liu that an AI-generated image created using Stable Diffusion with over 150 prompts constitutes a copyrightable work under Chinese Copyright Law, granting authorship rights to the human prompter based on their intellectual contribution through deliberate prompt selection, arrangement, and parameter adjustment. This landmark decision contrasts sharply with U.S. Copyright Office rulings that reject copyright protection for AI-prompted works, establishing China as taking a more permissive approach to AI-generated content copyright eligibility."

- title: "Meta's $14.3 Billion Scale AI Investment"
  date: "2025-06-12T09:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["Meta"]
  models: []
  impact_areas: ["Market Competition"]
  key_figures: ["Mark Zuckerberg", "Alexandr Wang"]
  link: "https://ai.plainenglish.io/meta-pays-14-3-billion-for-superintelligence-28-year-old-college-dropout-ceo-in-charge-3fc950b6e12a"
  description: "Meta Platforms announced a landmark $14.3 billion investment to acquire a 49% stake in Scale AI, valuing the data-labeling startup at over $29 billion. As part of the deal, Scale's 28-year-old co-founder and CEO Alexandr Wang joined Meta to lead a new 'Superintelligence' lab focused on achieving artificial general intelligence (AGI). This acquisition represents one of the largest AI-focused investments in history and signals Meta's aggressive push to compete with OpenAI and Google in the race for advanced AI capabilities, particularly following disappointing performance of its Llama 4 models."

- title: "OpenAI o1 and o1-mini Release"
  date: "2024-09-12T10:00:00-07:00"
  tags: ["Model", "Product", ]
  organizations: ["OpenAI"]
  models: ["o1", "o1-mini"]
  impact_areas: ["Reasoning AI", "Multimodal AI"]
  key_figures: []
  link: "https://openai.com/index/introducing-openai-o1-preview/"
  description: "OpenAI released o1 (codenamed 'Strawberry') and o1-mini, breakthrough reasoning models that spend more time thinking before responding. The o1 model demonstrated remarkable performance improvements, scoring 83% on International Mathematics Olympiad qualifying exams compared to GPT-4o's 13%, and ranking in the 89th percentile on competitive programming questions. These models represent a significant advancement in AI's ability to tackle complex multi-step problems in mathematics, science, and coding through enhanced chain-of-thought reasoning."

- title: "Claude 3.5 Sonnet Release"
  date: "2024-06-20T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude 3.5 Sonnet"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://www.anthropic.com/news/claude-3-5-sonnet"
  description: "Anthropic released Claude 3.5 Sonnet, setting new industry benchmarks for intelligence while operating at twice the speed of Claude 3 Opus. The model achieved graduate-level reasoning performance (59.4% on GPQA) and undergraduate-level knowledge (88.7% on MMLU), with particularly strong coding capabilities (64% on HumanEval). Claude 3.5 Sonnet excelled in visual reasoning tasks like interpreting charts and graphs, making it highly effective for business analytics and software development applications."

- title: "Claude 4 Opus and Sonnet Release"
  date: "2025-05-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude 4 Opus", "Claude 4 Sonnet"]
  impact_areas: ["Reasoning AI", "Multimodal AI"]
  key_figures: []
  link: "https://www.anthropic.com/news/claude-4"
  description: "Anthropic launched Claude 4, featuring both Opus and Sonnet variants with enhanced reasoning capabilities and safety features. Claude 4 Opus represents Anthropic's most powerful model with superior reasoning and advanced coding abilities, while Claude 4 Sonnet offers high-performance capabilities with exceptional efficiency. Both models feature extended thinking capabilities, improved safety guardrails, and enhanced multimodal processing, setting new standards in complex reasoning and advanced coding tasks."

- title: "OpenAI Forms 'Superalignment' Team to Tackle Control of Super-Intelligent AI"
  date: "2023-07-05T00:00:00-00:00"
  tags: ["Alignment Research", "Governance"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["AI Safety", "Long-term Governance"]
  key_figures: ["Ilya Sutskever", "Jan Leike"]
  link: "https://techcrunch.com/2023/07/05/openai-is-forming-a-new-team-to-bring-superintelligent-ai-under-control/"
  description: "OpenAI announced a dedicated Superalignment team that will receive 20% of the company's secured compute over the next four years to develop scalable oversight, robustness, and interpretability techniques capable of steering AI systems that exceed human intelligence."

- title: "ChatGPT Code Interpreter Beta Released to All Plus Subscribers"
  date: "2023-07-06T00:00:00-00:00"
  tags: ["Product Launch", "Developer Tools"]
  organizations: ["OpenAI"]
  models: ["GPT-4 (Code Interpreter)"]
  impact_areas: ["Data Analysis", "Software Engineering"]
  key_figures: []
  link: "https://medium.com/the-ai-archives/chatgpts-new-code-interpreter-and-what-it-means-for-you-998881ee5cc9"
  description: "OpenAI rolled out the Code Interpreter beta—an interactive Python sandbox with file-upload support—to all ChatGPT Plus users, enabling on-the-fly data analysis, visualization, and code execution directly inside the chat interface."

- title: "Anthropic Releases Claude 2 with Public Beta and API Access"
  date: "2023-07-11T00:00:00-00:00"
  tags: ["Model Release"]
  organizations: ["Anthropic"]
  models: ["Claude 2"]
  impact_areas: ["Enterprise AI", "Reasoning Assistants"]
  key_figures: ["Dario Amodei"]
  link: "https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot/"
  description: "Claude 2 delivers stronger reasoning, coding, and math skills, a 100K-token context window, and is now accessible via claude.ai for U.S. and U.K. users as well as through a paid API, positioning Anthropic as a direct competitor to OpenAI's GPT-4."

- title: "OpenAI Adds Function-Calling and 16K Context to GPT-3.5-Turbo and GPT-4"
  date: "2023-06-13T00:00:00-00:00"
  tags: ["API Update"]
  organizations: ["OpenAI"]
  models: ["GPT-3.5-Turbo-0613", "GPT-4-0613"]
  impact_areas: ["Tool Integration", "Structured Outputs"]
  key_figures: []
  link: "https://cobusgreyling.medium.com/openai-function-calling-98fbf9539d2a"
  description: "OpenAI introduced native JSON function-calling, model versions fine-tuned for tool use, an optional 16K-token context window for GPT-3.5-Turbo, and price reductions—making it easier for developers to build agentic workflows and plugin-style applications."