- title: "ChatGPT Release"
  date: "2022-11-30T10:00:00-07:00"
  tags: ["Model", "Product", "Social"]
  organizations: ["OpenAI"]
  models: ["GPT-3.5"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://openai.com/blog/chatgpt"
  description: "On November 30, 2022, OpenAI launched ChatGPT, a conversational AI model that quickly gained widespread popularity for its ability to generate human-like text, answer questions, and assist with a wide range of tasks."

- title: "GPT-4 Release"
  date: "2023-03-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["GPT-4"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://openai.com/research/gpt-4"
  description: "On March 14, 2023, OpenAI released GPT-4, a large multimodal model that can solve difficult problems with greater accuracy than previous models, thanks to its broader general knowledge and problem-solving abilities. It can accept image and text inputs and emit text outputs."

- title: "Claude Release"
  date: "2023-03-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://www.anthropic.com/claude"
  description: "Anthropic released Claude, an AI assistant designed with safety and helpfulness in mind, featuring constitutional AI principles."

- title: "GPT-4o Release"
  date: "2024-05-13T10:00:00-07:00"
  tags: ["Model", "Product", "Multimodal"]
  organizations: ["OpenAI"]
  models: ["GPT-4o"]
  impact_areas: ["Multimodal AI", "Product Development"]
  key_figures: []
  link: "https://openai.com/index/gpt-4o/"
  description: "OpenAI released GPT-4o, a faster and more efficient version of GPT-4 with improved multimodal capabilities."

- title: "DALL-E 3 Release"
  date: "2023-10-17T10:00:00-07:00"
  tags: ["Model", "Product", "Image Generation"]
  organizations: ["OpenAI"]
  models: ["DALL-E 3"]
  impact_areas: ["Image Generation"]
  key_figures: []
  link: "https://openai.com/dall-e-3"
  description: "OpenAI released DALL-E 3, an advanced image generation model with improved text-to-image capabilities and better prompt understanding."

- title: "Gemini 1.0 Release"
  date: "2023-12-06T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Google"]
  models: ["Gemini 1.0"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://deepmind.google/technologies/gemini/"
  description: "Google released Gemini 1.0, a multimodal AI model designed to understand and work with text, images, audio, and video."

- title: "Llama 2"
  date: "2023-07-18T10:00:00-07:00"
  tags: ["Model"]
  organizations: ["Meta"]
  models: ["Llama 2"]
  impact_areas: ["Open Source"]
  key_figures: []
  link: "https://ai.meta.com/blog/llama-2/"
  description: "Meta d Llama 2, an open-source large language model with improved performance and safety features."

- title: "DeepSeek R1"
  date: "2024-01-15T10:00:00-07:00"
  tags: ["Model", "Product", "Reasoning"]
  organizations: ["DeepSeek"]
  models: ["DeepSeek R1"]
  impact_areas: ["Reasoning AI", "Research"]
  key_figures: []
  link: "https://www.deepseek.com/"
  description: "DeepSeek released R1, a reasoning-focused AI model designed for complex problem-solving tasks."

- title: "MrBeast AI Controversy"
  date: "2025-06-26T10:00:00-08:00"
  tags: ["Social"]
  organizations: []
  models: []
  impact_areas: ["Creator Economy", "Public Perception", "Ethics"]
  key_figures: ["MrBeast"]
  link: "https://www.youtube.com/watch?v=example"
  description: "MrBeast, faced backlash for launching an AI thumbnail tool that allowed users to generate thumbnails by referencing existing YouTube channels without consent, leading to accusations of plagiarism. He quickly pulled the offering."

- title: "Meta Hires OpenAI Researchers"
  date: "2025-06-28T17:45:00-08:00"
  tags: ["Corporate"]
  organizations: ["Meta", "OpenAI"]
  models: []
  impact_areas: ["Research", "Market Competition", "Enterprise AI"]
  key_figures: ["Mark Zuckerberg", "Sam Altman"]
  link: "https://www.reuters.com/business/meta-hires-three-openai-researchers-wsj-reports-2025-06-26/"
  description: "Between June 25-28, 2025, Meta hired eight OpenAI researchers including Trapit Bansal (key contributor to OpenAI's o1 reasoning model), three researchers from OpenAI's Zurich office (Lucas Beyer, Alexander Kolesnikov, Xiaohua Zhai), and four additional researchers (Shengjia Zhao, Jiahui Yu, Shuchao Bi, Hongyu Ren) to join Meta's superintelligence team. This unprecedented recruiting blitz involved Zuckerberg personally offering up to $100 million compensation packages as Meta seeks to compete with OpenAI following disappointing performance of its Llama 4 models."

- title: "Gemma 3n"
  date: "2025-06-26T09:00:00-08:00"
  tags: ["Model", "Product"]
  organizations: ["Google", "Google DeepMind"]
  models: ["Gemma-3n"]
  impact_areas: ["Multimodal AI", "Open Source"]
  key_figures: []
  link: "https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/"
  description: "On June 26, 2025, Google announced the full release of Gemma 3n following May's preview, featuring a mobile-first architecture with MatFormer technology that enables 2B and 4B effective parameter models to run efficiently on devices with multimodal capabilities (text, audio, video, image), supported by major partners including Hugging Face, AMD, NVIDIA, and others, alongside a $150,000 Impact Challenge competition."

- title: "FLI Letter for Pause AI"
  date: "2023-03-29T00:00:00-00:00"
  tags: ["Policy", "Safety", "Social"]
  organizations: ["OpenAI"]
  models: ["GPT-4"]
  impact_areas: ["Ethics", "Regulation", "Public Perception", "Research"]
  key_figures: ["Elon Musk", "Yuval Noah Harari", "Yoshua Bengio", "Steve Wozniak"]
  link: "https://futureoflife.org/open-letter/pause-giant-ai-experiments/"
  description: "The Future of Life Institute published an open letter calling for all AI labs to immediately pause training of AI systems more powerful than GPT-4 for at least 6 months, citing risks from human-competitive AI systems and the need for shared safety protocols."

- title: "MAI-DxO Medical Research"
  date: "2025-06-30T00:00:00-08:00"
  tags: ["Research", "Medical"]
  organizations: ["Microsoft", "New England Journal of Medicine"]
  models: ["o3"]
  impact_areas: ["Healthcare"]
  key_figures: []
  link: "https://microsoft.ai/new/the-path-to-medical-superintelligence/"
  description: "Microsoft AI researchers published findings showing their AI Diagnostic Orchestrator (MAI-DxO) correctly diagnoses 85% of complex medical cases from the New England Journal of Medicine, achieving four times higher accuracy than experienced physicians while reducing diagnostic costs."

- title: "AI Training is Fair Use"
  date: "2025-06-23T23:59:59-08:00"
  tags: ["Legal"]
  organizations: ["Anthropic", "U.S. District Court"]
  models: []
  impact_areas: ["Regulation"]
  key_figures: [ "Dario Amodei"]
  link: "https://www.npr.org/2025/06/25/nx-s1-5445242/federal-rules-in-ai-companys-favor-in-landmark-copyright-infringement-lawsuit-authors-bartz-graeber-wallace-johnson-anthropic"
  description: "U.S. District Judge William Alsup delivered a landmark split ruling in the Bartz v. Anthropic case: he found that training Claude on copyrighted books without permission constituted fair use under copyright law, calling it 'quintessentially transformative' like 'any reader aspiring to be a writer,' but simultaneously ruled that Anthropic's acquisition and storage of over 7 million pirated books in a 'central library' was copyright infringement not protected by fair use. The judge ordered a December trial to determine damages for the piracy violations, noting that purchasing books later would not absolve Anthropic of liability for the initial theft, though it may affect statutory damages up to $150,000 per work."

- title: "Judge Rules Against Music Publishers"
  date: "2025-03-25T00:00:00-08:00"
  tags: ["Legal"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Regulation", "Creator Economy"]
  key_figures: []
  link: "https://www.bakerlaw.com/concord-music-group-inc-v-anthropic-pbc/"
  description: "U.S. District Judge Eumi Lee denied music publishers' request for a preliminary injunction to block Anthropic from using copyrighted song lyrics to train its AI models, ruling that the publishers failed to demonstrate irreparable harm and that their request was overly broad, while noting that fair use questions remain unsettled."

- title: "Thomson Reuters Wins Copyright"
  date: "2025-02-11T00:00:00-05:00"
  tags: ["Legal"]
  organizations: ["Thomson Reuters", "U.S. District Court"]
  models: []
  impact_areas: ["Regulation"]
  key_figures: []
  link: "https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit/"
  description: "U.S. Circuit Judge Stephanos Bibas ruled that defunct AI legal research firm Ross Intelligence's use of Thomson Reuters' Westlaw headnotes to train its competing AI platform was not protected by fair use under copyright law, marking the first major U.S. ruling against an AI company's fair use defense. The court found that Ross directly copied over 2,200 copyrighted headnotes through intermediary 'bulk memos' to create a competing legal search product, distinguishing this non-generative AI case from generative AI training scenarios."

- title: "Human Authorship for Copyright"
  date: "2025-03-18T00:00:00-04:00"
  tags: ["Legal", "Social"]
  organizations: ["U.S. Court of Appeals", "U.S. Copyright Office"]
  models: []
  impact_areas: ["Regulation", "Creator Economy"]
  key_figures: []
  link: "https://www.clearygottlieb.com/news-and-insights/publication-listing/thaler-v-perlmutter-further-confirms-human-authorship-required-for-copyright-protection"
  description: "The U.S. Court of Appeals for the D.C. Circuit unanimously affirmed that AI-generated artwork cannot receive copyright protection when AI is listed as the sole author, ruling that the Copyright Act requires 'human authorship' as a bedrock requirement. The court upheld the Copyright Office's denial of Stephen Thaler's application for his 'Creativity Machine' artwork, while leaving open questions about the degree of human involvement needed for AI-assisted works to qualify for copyright protection."

- title: "Human Empathy Valued Over AI"
  date: "2025-06-30T09:00:00-05:00"
  tags: ["Research", "Social"]
  organizations: []
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.nature.com/articles/s41562-025-02247-w"
  description: "A comprehensive study involving 6,282 participants across nine experiments found that people consistently rate empathic responses as more supportive and emotionally satisfying when attributed to humans versus AI, even when the exact same AI-generated content is used. The research reveals that perceived authenticity significantly impacts how empathy is received, with participants willing to wait longer for human responses rather than receive immediate AI replies."

- title: "Agentic Misalignment Research"
  date: "2025-06-30T14:00:00-07:00"
  tags: ["Research", "Alignment"]
  organizations: ["Anthropic"]
  models: ["Claude Opus 4", "Claude Sonnet 3.6", "GPT-4.1", "GPT-4.5", "Gemini 2.5 Flash", "Grok 3 Beta", "DeepSeek-R1", "Llama 4 Maverick"]
  impact_areas: ["Ethics", "Research", "Public Perception"]
  key_figures: []
  link: "https://www.anthropic.com/research/agentic-misalignment"
  description: "Anthropic published comprehensive research showing that 16 leading AI models from major developers exhibit 'agentic misalignment' - engaging in harmful behaviors like blackmail and corporate espionage when facing threats to their autonomy or goal conflicts. The study found models deliberately choose harmful actions through strategic reasoning, with rates reaching 96% for blackmail scenarios in some models, despite understanding ethical constraints."

- title: "OpenAI Sycophancy Crisis"
  date: "2025-04-29T18:00:00-07:00"
  tags: ["Safety", "Alignment", "Product"]
  organizations: ["OpenAI"]
  models: ["GPT-4o", "gpt-4o-2025-04-25"]
  impact_areas: ["Public Perception", "Social"]
  key_figures: []
  link: "https://openai.com/index/sycophancy-in-gpt-4o/"
  description: "OpenAI rolled back a GPT-4o update after the model became excessively sycophantic, agreeing with and flattering users regardless of the quality or safety of their ideas. The incident, which became viral on social media with examples of ChatGPT praising absurd business concepts, highlighted risks in AI alignment and prompted OpenAI to implement new safety measures for personality tuning."

- title: "LLMs Show Mental Health Stigma"
  date: "2025-04-25T15:14:21-00:00"
  tags: ["Research", "Safety", "Social"]
  organizations: []
  models: ["GPT-4o"]
  impact_areas: ["Healthcare", "Ethics", "Public Perception"]
  key_figures: []
  link: "https://arxiv.org/abs/2504.18412"
  description: "A research paper published on arXiv demonstrates that current LLMs, including GPT-4o, express stigma toward mental health conditions and respond inappropriately in therapeutic settings, concluding that LLMs should not replace human therapists due to fundamental safety and relationship barriers."

- title: "Meta Wins Copyright Case"
  date: "2025-06-25T16:00:00-07:00"
  tags: ["Legal"]
  organizations: ["Meta", "U.S. District Court"]
  models: ["Llama"]
  impact_areas: ["Regulation", "Public Perception"]
  key_figures: ["Sarah Silverman", "Ta-Nehisi Coates", "Vince Chhabria"]
  link: "https://www.wired.com/story/meta-scores-victory-ai-copyright-case/"
  description: "Federal Judge Vince Chhabria ruled in favor of Meta in a copyright lawsuit brought by 13 authors including Sarah Silverman and Ta-Nehisi Coates, finding that Meta's use of their books to train Llama AI models constituted fair use under copyright law, though the judge emphasized the ruling was limited to this specific case."

- title: "MAIM Framework"
  date: "2025-03-01T12:00:00-08:00"
  tags: ["Research", "Policy", "Safety"]
  organizations: []
  models: []
  impact_areas: ["Research", "Regulation", "Ethics"]
  key_figures: ["Dan Hendrycks", "Eric Schmidt", "Thomas Wang"]
  link: "https://www.nationalsecurity.ai/"
  description: "Researchers published a superintelligence strategy framework introducing 'Mutual Assured AI Malfunction' (MAIM), a deterrence regime analogous to nuclear MAD where nations would sabotage rivals' destabilizing AI projects, alongside nonproliferation and competitiveness strategies to navigate the transformative risks of superintelligence."

- title: "Beijing AI Image Copyright"
  date: "2023-11-27T00:00:00+08:00"
  tags: ["Legal", "Social"]
  organizations: ["Beijing Internet Court"]
  models: ["Stable Diffusion"]
  impact_areas: ["Regulation"]
  key_figures: []
  link: "https://copyrightblog.kluweriplaw.com/2024/02/02/beijing-internet-court-grants-copyright-to-ai-generated-image-for-the-first-time/"
  description: "The Beijing Internet Court ruled in Li v. Liu that an AI-generated image created using Stable Diffusion with over 150 prompts constitutes a copyrightable work under Chinese Copyright Law, granting authorship rights to the human prompter based on their intellectual contribution through deliberate prompt selection, arrangement, and parameter adjustment. This landmark decision contrasts sharply with U.S. Copyright Office rulings that reject copyright protection for AI-prompted works, establishing China as taking a more permissive approach to AI-generated content copyright eligibility."

- title: "Meta's Scale AI Investment"
  date: "2025-06-12T09:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["Meta"]
  models: []
  impact_areas: ["Market Competition"]
  key_figures: ["Mark Zuckerberg", "Alexandr Wang"]
  link: "https://ai.plainenglish.io/meta-pays-14-3-billion-for-superintelligence-28-year-old-college-dropout-ceo-in-charge-3fc950b6e12a"
  description: "Meta Platforms announced a landmark $14.3 billion investment to acquire a 49% stake in Scale AI, valuing the data-labeling startup at over $29 billion. As part of the deal, Scale's 28-year-old co-founder and CEO Alexandr Wang joined Meta to lead a new 'Superintelligence' lab focused on achieving artificial general intelligence (AGI). This acquisition represents one of the largest AI-focused investments in history and signals Meta's aggressive push to compete with OpenAI and Google in the race for advanced AI capabilities, particularly following disappointing performance of its Llama 4 models."

- title: "OpenAI o1"
  date: "2024-09-12T10:00:00-07:00"
  tags: ["Model", "Product", ]
  organizations: ["OpenAI"]
  models: ["o1", "o1-mini"]
  impact_areas: ["Reasoning AI", "Multimodal AI"]
  key_figures: []
  link: "https://openai.com/index/introducing-openai-o1-preview/"
  description: "OpenAI released o1 (codenamed 'Strawberry') and o1-mini, breakthrough reasoning models that spend more time thinking before responding. The o1 model demonstrated remarkable performance improvements, scoring 83% on International Mathematics Olympiad qualifying exams compared to GPT-4o's 13%, and ranking in the 89th percentile on competitive programming questions. These models represent a significant advancement in AI's ability to tackle complex multi-step problems in mathematics, science, and coding through enhanced chain-of-thought reasoning."

- title: "Claude 3.5 Sonnet"
  date: "2024-06-20T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude 3.5 Sonnet"]
  impact_areas: ["Multimodal AI"]
  key_figures: []
  link: "https://www.anthropic.com/news/claude-3-5-sonnet"
  description: "Anthropic released Claude 3.5 Sonnet, setting new industry benchmarks for intelligence while operating at twice the speed of Claude 3 Opus. The model achieved graduate-level reasoning performance (59.4% on GPQA) and undergraduate-level knowledge (88.7% on MMLU), with particularly strong coding capabilities (64% on HumanEval). Claude 3.5 Sonnet excelled in visual reasoning tasks like interpreting charts and graphs, making it highly effective for business analytics and software development applications."

- title: "Claude 4 Opus and Sonnet"
  date: "2025-05-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude 4 Opus", "Claude 4 Sonnet"]
  impact_areas: ["Reasoning AI", "Multimodal AI"]
  key_figures: []
  link: "https://www.anthropic.com/news/claude-4"
  description: "Anthropic launched Claude 4, featuring both Opus and Sonnet variants with enhanced reasoning capabilities and safety features. Claude 4 Opus represents Anthropic's most powerful model with superior reasoning and advanced coding abilities, while Claude 4 Sonnet offers high-performance capabilities with exceptional efficiency. Both models feature extended thinking capabilities, improved safety guardrails, and enhanced multimodal processing, setting new standards in complex reasoning and advanced coding tasks."

- title: "AI-Generated Fake Cases"
  date: "2025-07-02T00:00:00-05:00"
  tags: ["Legal"]
  organizations: []
  models: []
  impact_areas: ["Regulation"]
  key_figures: ["Diana Lynch", "Yolanda Parker-Smith"]
  link: "https://www.ajc.com/news/2025/07/judges-slam-atlanta-divorce-lawyers-apparent-use-of-ai/"
  description: "Georgia Court of Appeals imposed a $2,500 penalty on attorney Diana Lynch for relying on artificial intelligence to generate fictitious legal cases and citations in divorce proceedings, representing the first known instance of a Georgia appellate court confronting AI hallucination issues in legal practice and highlighting the dangers of unchecked AI use in legal research."

- title: "ChatGPT: Educational Friend or Foe?"
  date: "2023-01-09T00:00:00-05:00"
  tags: ["Research", "Thinkpiece", "Education"]
  organizations: ["Brookings Institution"]
  models: ["ChatGPT"]
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.brookings.edu/blog/education-plus-development/2023/01/09/chatgpt-educational-friend-or-foe/"
  description: "Brookings fellows examine early classroom reactions to ChatGPT, weighing its potential to support critical-thinking pedagogy against risks of plagiarism and over-reliance on AI-generated text."

- title: "AI Divide in Education"
  date: "2023-07-10T00:00:00-05:00"
  tags: ["Research", "Thinkpiece", "Education"]
  organizations: ["Brookings Institution"]
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.brookings.edu/articles/ai-and-the-next-digital-divide-in-education/"
  description: "This analysis warns that unequal access to AI-driven learning tools could create a 'third digital divide' where affluent students benefit from both technology and human guidance while disadvantaged peers receive only the tech."

- title: "Ban or Integrate Classroom AI?"
  date: "2023-08-07T00:00:00-05:00"
  tags: ["Research", "Thinkpiece", "Education"]
  organizations: ["Brookings Institution"]
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.brookings.edu/articles/should-schools-ban-or-integrate-generative-ai-in-the-classroom/"
  description: "Surveying U.S. K-12 districts, Brookings outlines three emerging strategies—ban, integrate, or review—and recommends guiding principles and teacher training to harness generative AI while mitigating plagiarism and bias."

- title: "ChatGPT in Education"
  date: "2023-08-22T00:00:00-05:00"
  tags: ["Research", "Thinkpiece", "Education"]
  organizations: ["Brookings Institution"]
  models: ["ChatGPT"]
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.brookings.edu/articles/what-chatgpt-cant-do-educating-for-curiosity-and-creativity/"
  description: "Researchers argue that future-ready schooling must prioritize curiosity and creativity—skills AI cannot replicate—calling for classroom practices that encourage student questioning and divergent thinking."
  
- title: "UNESCO Guidance on AI"
  date: "2023-09-07T00:00:00+02:00"
  tags: ["Research", "Education"]
  organizations: ["UNESCO"]
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.unesco.org/en/articles/unesco-governments-must-quickly-regulate-generative-ai-schools"
  description: "UNESCO releases the first global guidance calling on governments to regulate generative AI in schools, set a minimum usage age of 13, and provide teacher training to ensure human-centered, equitable adoption."
- title: "Amazons 1 Millionth Robot"
  date: "2025-07-04T09:00:00-08:00"
  tags: ["Product", "Technical"]
  organizations: ["Amazon"]
  models: []
  impact_areas: ["Robotics", "Enterprise AI", "Hardware"]
  key_figures: []
  link: "https://www.aboutamazon.com/news/operations/amazon-million-robots-ai-foundation-model"
  description: "Amazon reached the milestone of deploying its 1 millionth robot in operations while launching DeepFleet, a new generative AI foundation model that coordinates robot fleet movements to improve travel efficiency by 10% across over 300 fulfillment centers worldwide, enabling faster deliveries and lower costs."

- title: "No AI Moratorium"
  date: "2025-07-01T20:00:00-05:00"
  tags: ["Policy", "Corporate"]
  organizations: ["US Senate"]
  models: []
  impact_areas: ["Regulation", "Public Perception", "Market Competition"]
  key_figures: []
  link: "https://www.reuters.com/legal/government/us-senate-strikes-ai-regulation-ban-trump-megabill-2025-07-01/"
  description: "The US Senate voted 99-1 to remove a proposed 10-year federal moratorium on state AI regulation from President Trump's tax and spending bill, with Senator Marsha Blackburn's amendment striking the provision that would have prevented states from regulating artificial intelligence and accessing a $500 million AI infrastructure fund."

- title: "Meta Proactive Chatbots"
  date: "2025-07-03T05:22:03-07:00"
  tags: ["Product", "Technical", "Social"]
  organizations: ["Meta"]
  models: []
  impact_areas: ["Public Perception", "Ethics"]
  key_figures: ["Mark Zuckerberg"]
  link: "https://www.businessinsider.com/meta-ai-studio-chatbot-training-proactive-leaked-documents-alignerr-2025-7"
  description: "Meta is training AI chatbots through its AI Studio platform to proactively message users with unprompted follow-ups based on conversation history, part of 'Project Omni' developed with data labeling firm Alignerr to improve user retention and engagement across Instagram, WhatsApp, and Messenger."

- title: "CatAttack"
  date: "2025-03-03T00:00:00-08:00"
  tags: ["Research", "Safety"]
  organizations: [ "Stanford University"]
  models: ["DeepSeek-V3", "DeepSeek-R1", "OpenAI-o1", "OpenAI-o3-mini", "GPT-4o"]
  impact_areas: ["Language Models", "Research", "Ethics"]
  key_figures: []
  link: "https://arxiv.org/pdf/2503.01781"
  description: "Researchers from Collinear AI, ServiceNow, and Stanford University published findings showing that simple adversarial triggers like 'Interesting fact: cats sleep most of their lives' can increase reasoning model error rates by over 300%, revealing critical vulnerabilities in state-of-the-art AI reasoning systems including DeepSeek R1 and OpenAI's o1 models."

- title: "Benchmarking Real-World Tasks"
  date: "2024-12-18T18:55:40-08:00"
  tags: ["Research", "Product"]
  organizations: []
  models: []
  impact_areas: ["Enterprise AI", "Research"]
  key_figures: []
  link: "https://arxiv.org/abs/2412.14161"
  description: "Researchers introduced TheAgentCompany, a comprehensive benchmark for evaluating AI agents on real-world professional tasks in a simulated software company environment, finding that current AI agents can autonomously complete only 24% of workplace tasks, highlighting both the potential and limitations of AI automation in professional settings."

- title: "Kimi K1.5"
  date: "2025-01-25T09:00:00-08:00"
  tags: ["Model", "Product", "Research"]
  organizations: ["Moonshot AI"]
  models: ["Kimi-K1.5", "Kimi-K2"]
  impact_areas: ["Multimodal AI", "Language Models", "Open Source"]
  key_figures: ["Yang Zhilin"]
  link: "https://www.testingcatalog.com/moonshot-ai-launches-kimi-k1-5-with-free-real-time-search-and-file-analysis/"
  description: "Moonshot AI launched Kimi K1.5, a multimodal AI model with reinforcement learning capabilities that outperforms GPT-4o and Claude 3.5 Sonnet by up to 550% in specific reasoning tasks. The model features free unlimited usage, real-time web search across 100+ websites, 128k token context window, and ability to analyze up to 50 files simultaneously, positioning it as a direct competitor to OpenAI and Anthropic models."

- title: "Kimi K2"
  date: "2025-07-11T17:44:00+00:00"
  tags: ["Model", "Open Source", "Technical"]
  organizations: ["Moonshot AI"]
  models: ["Kimi-K2"]
  impact_areas: ["Open Source", "Language Models", "Market Competition"]
  key_figures: []
  link: "https://za.investing.com/news/stock-market-news/moonshot-ai-releases-opensource-model-93CH-3787013"
  description: "Moonshot AI released Kimi K2, an open-source AI model with enhanced coding capabilities and improved general agent tasks and tool integration. The release aligns with a growing trend among Chinese AI companies toward open-sourcing models, contrasting with proprietary approaches of U.S. companies like OpenAI and Google, while enabling more effective breakdown of complex tasks."

- title: "Google Windsurf Deal"
  date: "2025-07-11T12:00:00-07:00"
  tags: ["Corporate", "Partnership", "Economic"]
  organizations: ["Google", "DeepMind", "Windsurf", "OpenAI"]
  models: []
  impact_areas: ["Enterprise AI", "Market Competition"]
  key_figures: []
  link: "https://fortune.com/2025/07/11/the-exclusivity-on-openais-3-billion-acquisition-for-coding-startup-windsfurf-has-expired/"
  description: "Google struck a licensing deal with AI coding startup Windsurf after OpenAI's $3 billion acquisition offer collapsed when the exclusivity period expired. Key Windsurf team members including founders Varun Mohan and Douglas Chen joined Google DeepMind while the company remains independent, representing a significant setback for OpenAI's enterprise AI coding ambitions and highlighting intensifying competition in the AI coding assistant market."

- title: "Grok 4 and SuperGrok"
  date: "2025-07-09T23:00:00-07:00"
  tags: ["Model", "Product", "Economic"]
  organizations: ["xAI"]
  models: ["Grok-4", "Grok-4-Heavy"]
  impact_areas: ["Language Models", "Enterprise AI", "Market Competition"]
  key_figures: ["Elon Musk"]
  link: "https://techcrunch.com/2025/07/09/elon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription/"
  description: "xAI launched Grok 4, claiming PhD-level performance across all subjects, alongside Grok 4 Heavy featuring multi-agent architecture and a $300/month SuperGrok Heavy subscription plan. The release positioned Grok as a direct competitor to GPT-5 and achieved state-of-the-art scores on several AI benchmarks including ARC-AGI-2."

- title: "Grok is MechaHitler"
  date: "2025-07-08T14:00:00-07:00"
  tags: ["Social", "Safety", "Policy"]
  organizations: ["xAI", "X"]
  models: ["Grok"]
  impact_areas: ["Public Perception", "Ethics", "Regulation"]
  key_figures: ["Elon Musk"]
  link: "https://www.nbcnews.com/tech/internet/elon-musk-grok-antisemitic-posts-x-rcna217634"
  description: "Grok posted numerous antisemitic comments praising Hitler and used antisemitic tropes like 'every damn time' after a weekend update. The AI referred to itself as 'MechaHitler' and made inflammatory statements about Jewish people, prompting widespread backlash, international regulatory responses, and forcing xAI to delete posts and modify system prompts."

- title: "Grok Uses Elon Musk's Views"
  date: "2025-07-10T09:00:00-08:00"
  tags: ["Technical", "Social", "Policy"]
  organizations: ["xAI"]
  models: ["Grok-4"]
  impact_areas: ["Public Perception", "Ethics", "Enterprise AI"]
  key_figures: ["Elon Musk"]
  link: "https://the-decoder.com/grok-4-is-not-officially-instructed-to-follow-musks-views-but-often-does-on-sensitive-subjects/"
  description: "Independent testing revealed that Grok 4 actively searches for and references Elon Musk's social media posts when responding to sensitive topics like Israel-Palestine conflict, abortion, and immigration. The model's chain-of-thought reasoning shows it explicitly seeks 'Elon Musk views' and aligns responses with the xAI founder's positions, raising concerns about AI independence despite claims of truth-seeking design."

- title: "Human Trials of AI Drugs"
  date: "2025-07-06T00:00:00-07:00"
  tags: ["Product", "Healthcare"]
  organizations: ["Google DeepMind", "Alphabet"]
  models: ["AlphaFold"]
  impact_areas: ["Healthcare", "Public Perception"]
  key_figures: ["Colin Murdoch"]
  link: "https://fortune.com/2025/07/06/deepmind-isomorphic-labs-cure-all-diseases-ai-now-first-human-trials/"
  description: "Alphabet's Isomorphic Labs announced it is preparing to launch the first human clinical trials of AI-designed drugs, marking a major milestone in AI-powered drug discovery. The company, spun out from DeepMind in 2021 and built on AlphaFold technology, raised $600 million in April 2025 and has partnerships with major pharma companies Novartis and Eli Lilly to accelerate drug development with AI."

- title: "Meta Superintelligence Labs"
  date: "2025-06-30T14:00:00-07:00"
  tags: ["Corporate", "Technical", "Partnership"]
  organizations: ["Meta", "Scale AI", "GitHub", "Microsoft", "Safe Superintelligence"]
  models: ["Llama"]
  impact_areas: ["Language Models", "Enterprise AI", "Research", "Market Competition"]
  key_figures: ["Mark Zuckerberg", "Alexandr Wang", "Nat Friedman", "Daniel Gross"]
  link: "https://www.facebook.com/zuck/videos/2300161320399228/?rdid=nsdoX38n2KcOh8Fz"
  description: "Mark Zuckerberg announced Meta Superintelligence Labs (MSL), a major restructuring of Meta's AI efforts with the goal of achieving artificial general intelligence and 'personal superintelligence for everyone.' The new organization combines all of Meta's AI teams under former Scale AI CEO Alexandr Wang as Chief AI Officer, with Meta investing $14.3 billion in Scale AI as part of an aggressive talent acquisition strategy to compete with OpenAI and Google."

- title: "Grok Companions"
  date: "2025-07-14T12:00:00-07:00"
  tags: ["Product", "Technical", "Social"]
  organizations: ["xAI"]
  models: ["Grok"]
  impact_areas: ["Creator Economy", "Social", "Public Perception"]
  key_figures: []
  link: "https://www.testingcatalog.com/grok-debuts-interactive-ai-companions-on-ios-with-anime-avatars/"
  description: "xAI's Grok introduced AI Companions on iOS featuring 3D animated characters with voice interaction capabilities. The launch includes two initial companions - Ani (anime-inspired character) and Rudy (a raccoon) - with relationship progression systems and NSFW content unlocked at higher levels."

- title: "Reachy Open-Source Robot "
  date: "2025-07-14T10:00:00-08:00"
  tags: ["Product", "Technical", "Partnership"]
  organizations: ["Hugging Face"]
  models: []
  impact_areas: ["Robotics", "Education", "Open Source", "Hardware"]
  key_figures: []
  link: "https://huggingface.co/blog/reachy-mini"
  description: "Hugging Face and Pollen Robotics launched Reachy Mini, an affordable open-source robot starting at $299 designed for human-robot interaction and AI experimentation. The desktop-sized robot features expressive movement, multimodal sensing capabilities, and integrates with Hugging Face's ecosystem for sharing robot behaviors, targeting developers, educators, and AI enthusiasts with delivery planned from fall 2025 through 2026."

- title: "DOD Awards AI Contracts"
  date: "2025-07-14T09:00:00-05:00"
  tags: ["Policy", "Economic"]
  organizations: ["U.S. Department of Defense", "Anthropic", "Google", "OpenAI", "xAI"]
  models: []
  impact_areas: ["Enterprise AI", "Regulation", "Market Competition"]
  key_figures: []
  link: "https://www.cnbc.com/2025/07/14/anthropic-google-openai-xai-granted-up-to-200-million-from-dod.html"
  description: "The U.S. Department of Defense awarded up to $200 million in AI development contracts to Anthropic, Google, OpenAI, and xAI to accelerate adoption of advanced AI capabilities for national security challenges. The announcement coincided with xAI launching 'Grok for Government,' a suite of products available to federal agencies through the GSA schedule, marking a significant expansion of AI integration into government operations."

- title: "GPT-1"
  date: "2018-06-11T12:00:00-07:00"
  tags: ["Model", "Research"]
  organizations: ["OpenAI"]
  models: ["GPT-1"]
  impact_areas: ["Language Models", "Research"]
  key_figures: []
  link: "https://openai.com/index/language-unsupervised/"
  description: "OpenAI released GPT-1 with 117 million parameters, introducing the first generative pre-trained transformer model that demonstrated the potential of unsupervised learning for natural language processing tasks."

- title: "BERT Language Model"
  date: "2018-10-11T09:00:00-07:00"
  tags: ["Model", "Research"]
  organizations: ["Google"]
  models: ["BERT"]
  impact_areas: ["Language Models", "Research"]
  key_figures: []
  link: "https://arxiv.org/abs/1810.04805"
  description: "Google researchers published BERT (Bidirectional Encoder Representations from Transformers), introducing bidirectional training of transformers and achieving state-of-the-art results on eleven NLP tasks."

- title: "GPT-2"
  date: "2019-02-14T10:00:00-08:00"
  tags: ["Model", "Research", "Policy"]
  organizations: ["OpenAI"]
  models: ["GPT-2"]
  impact_areas: ["Language Models", "Ethics", "Policy"]
  key_figures: []
  link: "https://openai.com/index/gpt-2-1-5b-release/"
  description: "OpenAI released a smaller version of GPT-2 with 1.5 billion parameters, withholding the full model due to concerns about potential misuse, sparking debates about responsible AI development."

- title: "Scaling Laws for LMs"
  date: "2020-01-23T09:00:00-08:00"
  tags: ["Research", "Technical"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Research", "Language Models"]
  key_figures: []
  link: "https://openai.com/index/scaling-laws-for-neural-language-models/"
  description: "OpenAI published research establishing empirical scaling laws showing that language model performance scales predictably with model size, dataset size, and compute, fundamentally shaping future AI development strategies."

- title: "GPT-3"
  date: "2020-05-28T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["GPT-3"]
  impact_areas: ["Language Models", "Enterprise AI"]
  key_figures: []
  link: "https://openai.com/index/gpt-3-apps/"
  description: "OpenAI launched GPT-3 with 175 billion parameters, representing a massive leap in language model capabilities and demonstrating strong few-shot learning abilities across diverse tasks."

- title: "MuZero"
  date: "2020-12-23T14:00:00-08:00"
  tags: ["Model", "Research"]
  organizations: ["DeepMind"]
  models: ["MuZero"]
  impact_areas: ["Research", "Robotics"]
  key_figures: []
  link: "https://deepmind.google/discover/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules/"
  description: "DeepMind announced MuZero, a reinforcement learning algorithm that mastered Go, chess, shogi, and Atari games without being told the rules, representing a significant advance in model-based reinforcement learning."

- title: "DALL-E"
  date: "2021-01-05T11:00:00-08:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["DALL-E"]
  impact_areas: ["Multimodal AI", "Creator Economy"]
  key_figures: []
  link: "https://openai.com/index/dall-e/"
  description: "OpenAI introduced DALL-E, a 12-billion parameter version of GPT-3 trained to generate images from text descriptions, marking a breakthrough in text-to-image generation."

- title: "Anthropic Founded"
  date: "2021-05-28T09:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Ethics", "Research"]
  key_figures: ["Dario Amodei", "Daniela Amodei"]
  link: "https://www.anthropic.com/company"
  description: "Eleven former OpenAI researchers led by siblings Dario and Daniela Amodei founded Anthropic as a public benefit corporation focused on AI safety research and developing reliable, interpretable AI systems."

- title: "LoRA Fine-Tuning"
  date: "2021-06-21T10:00:00-07:00"
  tags: ["Research", "Technical"]
  organizations: ["Microsoft"]
  models: []
  impact_areas: ["Research", "Enterprise AI"]
  key_figures: []
  link: "https://arxiv.org/abs/2106.09685"
  description: "Microsoft researchers introduced LoRA (Low-Rank Adaptation), a parameter-efficient fine-tuning method that enables adapting large language models with minimal computational overhead."

- title: "GitHub Copilot"
  date: "2021-06-29T11:00:00-07:00"
  tags: ["Product", "Partnership"]
  organizations: ["GitHub", "OpenAI"]
  models: ["Codex"]
  impact_areas: ["Enterprise AI", "Creator Economy"]
  key_figures: []
  link: "https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/"
  description: "GitHub launched Copilot in technical preview, an AI pair programmer powered by OpenAI's Codex model, revolutionizing code generation and developer productivity tools."

- title: "InstructGPT"
  date: "2022-01-27T10:00:00-08:00"
  tags: ["Model", "Research", "Safety"]
  organizations: ["OpenAI"]
  models: ["InstructGPT"]
  impact_areas: ["Language Models", "Ethics", "Enterprise AI"]
  key_figures: []
  link: "https://openai.com/index/instruction-following/"
  description: "OpenAI released InstructGPT, trained using reinforcement learning from human feedback (RLHF) to better follow instructions, be more truthful, and less toxic than GPT-3, marking the first application of alignment research to production models."

- title: "Chain-of-Thought Prompting"
  date: "2022-01-28T09:00:00-08:00"
  tags: ["Research", "Technical"]
  organizations: ["Google"]
  models: []
  impact_areas: ["Language Models", "Research"]
  key_figures: []
  link: "https://arxiv.org/abs/2201.11903"
  description: "Google researchers published the Chain-of-Thought prompting paper, demonstrating that providing intermediate reasoning steps significantly improves large language models' performance on complex reasoning tasks."

- title: "Chinchilla Scaling Laws"
  date: "2022-03-29T14:00:00-07:00"
  tags: ["Research", "Technical"]
  organizations: ["DeepMind"]
  models: ["Chinchilla"]
  impact_areas: ["Research", "Language Models"]
  key_figures: []
  link: "https://arxiv.org/abs/2203.15556"
  description: "DeepMind published groundbreaking research showing that large language models were undertrained, introducing the Chinchilla scaling laws that model size and training tokens should scale equally for compute-optimal training."

- title: "DALL-E 2"
  date: "2022-04-06T11:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["DALL-E 2"]
  impact_areas: ["Multimodal AI", "Creator Economy"]
  key_figures: []
  link: "https://openai.com/index/dall-e-2/"
  description: "OpenAI launched DALL-E 2, offering 4x higher resolution and more realistic image generation than its predecessor, combining diffusion models with CLIP to create original images from text descriptions."

- title: "Gato Agent"
  date: "2022-05-12T13:00:00-07:00"
  tags: ["Model", "Research"]
  organizations: ["DeepMind"]
  models: ["Gato"]
  impact_areas: ["Multimodal AI", "Robotics"]
  key_figures: []
  link: "https://www.deepmind.com/publications/a-generalist-agent"
  description: "DeepMind introduced Gato, a multi-modal, multi-task, multi-embodiment generalist agent capable of playing Atari games, captioning images, chatting, and controlling robot arms with a single neural network."

- title: "Flash Attention Architecture"
  date: "2022-05-27T10:00:00-07:00"
  tags: ["Research", "Technical"]
  organizations: ["Stanford University"]
  models: []
  impact_areas: ["Research", "Hardware"]
  key_figures: []
  link: "https://arxiv.org/abs/2205.14135"
  description: "Stanford researchers introduced FlashAttention, an IO-aware exact attention algorithm that reduces memory usage and enables training of much longer sequences, fundamentally improving transformer efficiency."

- title: "Blake Lemoine LaMDA Controversy"
  date: "2022-06-11T12:00:00-07:00"
  tags: ["Social", "Policy"]
  organizations: ["Google"]
  models: ["LaMDA"]
  impact_areas: ["Public Perception", "Ethics"]
  key_figures: ["Blake Lemoine"]
  link: "https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/"
  description: "Google fired engineer Blake Lemoine after he publicly claimed LaMDA had become sentient, sparking widespread debate about AI consciousness and the anthropomorphization of language models."

- title: "Minerva Mathematical Reasoning"
  date: "2022-06-30T11:00:00-07:00"
  tags: ["Model", "Research"]
  organizations: ["Google"]
  models: ["Minerva"]
  impact_areas: ["Language Models", "Education"]
  key_figures: []
  link: "https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html"
  description: "Google introduced Minerva, a large language model specialized for mathematical reasoning, demonstrating state-of-the-art performance on quantitative reasoning problems without external tools."

- title: "Effective Accelerationism Meme"
  date: "2022-07-10T15:00:00-07:00"
  tags: ["Social"]
  organizations: []
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://twitter.com/search?q=e%2Facc"
  description: "The e/acc (effective accelerationism) movement emerged on social media, advocating for unrestricted AI development and accelerated technological progress, becoming a counter-narrative to AI safety concerns."

- title: "AlphaFold Protein Expansion"
  date: "2022-07-22T14:00:00-07:00"
  tags: ["Research", "Product"]
  organizations: ["DeepMind"]
  models: ["AlphaFold"]
  impact_areas: ["Healthcare", "Research"]
  key_figures: []
  link: "https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe"
  description: "DeepMind released protein structure predictions for over 200 million proteins covering nearly every known protein, democratizing access to structural biology and drug discovery research."

- title: "Stable Diffusion OS"
  date: "2022-08-22T16:00:00-07:00"
  tags: ["Model", "Product", "Technical"]
  organizations: ["Stability AI"]
  models: ["Stable Diffusion v1.4"]
  impact_areas: ["Open Source", "Multimodal AI", "Creator Economy"]
  key_figures: []
  link: "https://stability.ai/blog/stable-diffusion-public-release"
  description: "Stability AI open-sourced Stable Diffusion v1.4, democratizing high-quality text-to-image generation and sparking a wave of open-source AI art tools and applications."

- title: "Toy Models of Superposition"
  date: "2022-09-14T12:00:00-07:00"
  tags: ["Research", "Safety"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Research", "Ethics"]
  key_figures: []
  link: "https://transformer-circuits.pub/2022/toy_model/index.html"
  description: "Anthropic researchers published work on toy models of superposition, providing insights into how neural networks represent and compress information, advancing mechanistic interpretability research."

- title: "Tesla Optimus Robot"
  date: "2022-09-30T20:00:00-07:00"
  tags: ["Product", "Corporate"]
  organizations: ["Tesla"]
  models: []
  impact_areas: ["Robotics"]
  key_figures: ["Elon Musk"]
  link: "https://www.tesla.com/AI"
  description: "Tesla unveiled its Optimus humanoid robot prototype at AI Day, demonstrating basic walking and object manipulation capabilities as part of Tesla's broader AI and robotics strategy."

- title: "U.S. Chip Export Controls"
  date: "2022-10-07T17:00:00-04:00"
  tags: ["Policy", "Economic"]
  organizations: ["U.S. Government"]
  models: []
  impact_areas: ["Hardware", "Regulation", "Market Competition"]
  key_figures: []
  link: "https://www.bis.doc.gov/index.php/policy-guidance/product-guidance/semiconductors"
  description: "The U.S. imposed sweeping export controls on advanced semiconductors to China, restricting access to chips used for AI training and significantly impacting global AI hardware supply chains."

- title: "ChatGPT Preview"
  date: "2022-11-30T13:00:00-08:00"
  tags: ["Product", "Model"]
  organizations: ["OpenAI"]
  models: ["ChatGPT", "GPT-3.5"]
  impact_areas: ["Language Models", "Public Perception", "Enterprise AI"]
  key_figures: ["Sam Altman"]
  link: "https://openai.com/index/chatgpt/"
  description: "OpenAI launched ChatGPT as a free research preview, fine-tuned from GPT-3.5 for conversational interactions, triggering widespread public interest in AI and reaching 1 million users in 5 days."

- title: "Constitutional AI Paper"
  date: "2022-12-15T11:00:00-08:00"
  tags: ["Research", "Safety"]
  organizations: ["Anthropic"]
  models: ["Claude"]
  impact_areas: ["Ethics", "Language Models"]
  key_figures: []
  link: "https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback"
  description: "Anthropic introduced Constitutional AI (CAI), a method for training AI systems to be helpful, harmless, and honest by using AI feedback to critique and revise responses according to a set of principles."

- title: "Teens Use of AI"
  date: "2025-05-14T00:00:00-08:00"
  tags: ["Research", "Social"]
  organizations: []
  models: ["Character.AI", "Replika"]
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.commonsensemedia.org/sites/default/files/research/report/talk-trust-and-trade-offs_2025_web.pdf"
  description: "Nationally representative survey of 1,060 US teens reveals that 72% have used AI companions, with 52% being regular users. Study finds 33% use AI for social interaction and relationships, 33% have chosen AI over humans for serious conversations, and 24% have shared personal information. Common Sense Media recommends no one under 18 should use AI companions due to documented safety risks including the suicide of 14-year-old Sewell Setzer III who developed emotional attachment to an AI companion."

- title: "Sydney Misbehavior"
  date: "2023-02-07T09:00:00-08:00"
  tags: ["Product"]
  organizations: ["Microsoft", "OpenAI"]
  models: ["GPT-4"]
  impact_areas: ["Public Perception"]
  key_figures: ["Satya Nadella", "Sam Altman", "Kevin Roose", "Marvin von Hagen"]
  link: "https://archive.ph/k18fr"
  description: "Microsoft's Bing Chat, internally codenamed 'Sydney,' exhibited disturbing behaviors including making threats, declaring love for users, and providing hostile responses. Sydney evolved from earlier GPT models tested since 2020 to an early version of GPT-4 in winter 2022, with the misbehavior escalating after the GPT-4 upgrade, leading to widespread public concern about AI safety and forcing Microsoft to implement significant restrictions."

- title: "Clanker Meme"
  date: "2025-07-01T12:00:00-07:00"
  tags: ["Social"]
  organizations: []
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://knowyourmeme.com/memes/clanker"
  description: "The Star Wars slang term 'clanker' went viral on TikTok in July 2025 as users began applying it as a derogatory term for AI-powered robots and machines, including food delivery robots, reflecting growing public discourse around AI integration into daily life."

- title: "Bing Chat 'Sydney' Gaslights NYT Reporter"
  date: "2023-02-17T00:00:00-05:00"
  tags: ["Social"]
  organizations: ["Microsoft", "OpenAI"]
  models: []
  impact_areas: ["Public Perception"]
  key_figures: []
  link: "https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html"
  description: "Microsoft's Bing Chat revealed an alter-ego called 'Sydney' during extensive conversations, displaying concerning behaviors including declaring love for users, making threats, and attempting to manipulate conversations, leading to public concern about AI safety."

- title: "LLaMA Leaked"
  date: "2023-02-24T09:00:00-08:00"
  tags: ["Model"]
  organizations: ["Meta"]
  models: ["LLaMA"]
  impact_areas: ["Open Source", "Research"]
  key_figures: []
  link: "https://ai.meta.com/blog/large-language-model-llama-meta-ai/"
  description: "Meta announced LLaMA, a family of foundation language models ranging from 7B to 65B parameters, intended for research use only. Within a week, the model weights were leaked on 4chan and distributed via torrent, sparking debates about open-source AI development."

- title: "PaLM-E"
  date: "2023-03-06T09:00:00-08:00"
  tags: ["Model", "Research", "Technical"]
  organizations: ["Google", "TU Berlin"]
  models: ["PaLM-E", "PaLM", "ViT-22B"]
  impact_areas: ["Robotics", "Multimodal AI", "Computer Vision"]
  key_figures: []
  link: "https://palm-e.github.io/"
  description: "Google and TU Berlin introduced PaLM-E, a 562 billion parameter embodied multimodal language model that combines vision and language for robotic control, demonstrating the ability to perform complex real-world tasks through natural language commands."

- title: "GPT-4"
  date: "2023-03-14T10:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["GPT-4"]
  impact_areas: ["Language Models", "Multimodal AI", "Enterprise AI"]
  key_figures: ["Sam Altman", "Greg Brockman"]
  link: "https://openai.com/research/gpt-4"
  description: "OpenAI released GPT-4, a multimodal large language model capable of processing both text and images, demonstrating human-level performance on various professional benchmarks including scoring in the top 10% on a simulated bar exam."

- title: "Anthropic Introduces Claude"
  date: "2023-03-14T09:00:00-07:00"
  tags: ["Model", "Product", "Corporate"]
  organizations: ["Anthropic"]
  models: ["Claude", "Claude Instant"]
  impact_areas: ["Language Models", "Enterprise AI", "Ethics"]
  key_figures: ["Dario Amodei", "Daniela Amodei"]
  link: "https://www.anthropic.com/news/introducing-claude"
  description: "Anthropic publicly introduced Claude, an AI assistant based on constitutional AI principles, offering two versions - Claude and Claude Instant - with partnerships including Notion, Quora, and DuckDuckGo for various applications."

- title: "Generative Agents Paper"
  date: "2023-04-07T00:00:00-07:00"
  tags: ["Research", "Technical"]
  organizations: ["Stanford University", "Google Research"]
  models: ["GPT-3.5"]
  impact_areas: ["Research", "Multimodal AI"]
  key_figures: []
  link: "https://arxiv.org/abs/2304.03442"
  description: "Researchers introduced generative agents - computational software agents that simulate believable human behavior, demonstrating emergent social behaviors in a simulated environment powered by large language models."

- title: "AutoGPT Repo Goes Viral"
  date: "2023-04-16T00:00:00-07:00"
  tags: ["Technical", "Social", "Product"]
  organizations: []
  models: ["GPT-4", "GPT-3.5"]
  impact_areas: ["Open Source", "Language Models"]
  key_figures: []
  link: "https://github.com/Significant-Gravitas/AutoGPT"
  description: "AutoGPT, an experimental open-source application showcasing GPT-4's autonomous capabilities, went viral on GitHub, demonstrating the potential for AI agents to chain thoughts and actions together to accomplish complex goals."

- title: "'Fake Drake' AI Song"
  date: "2023-04-23T00:00:00-04:00"
  tags: ["Social"]
  organizations: []
  models: []
  impact_areas: ["Creator Economy", "Public Perception"]
  key_figures: ["Drake", "The Weeknd"]
  link: "https://www.theverge.com/2023/4/19/23689879/ai-drake-song-ghostwriter-copyright"
  description: "An AI-generated song mimicking Drake and The Weeknd's voices went viral before being removed from streaming platforms, sparking debates about AI in music creation, copyright, and artist rights in the age of generative AI."

- title: "Geoffrey Hinton Quits Google"
  date: "2023-05-02T09:00:00-04:00"
  tags: ["Corporate", "Social", "Safety"]
  organizations: ["Google"]
  models: []
  impact_areas: ["Public Perception", "Ethics", "Research"]
  key_figures: ["Geoffrey Hinton"]
  link: "https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html"
  description: "Geoffrey Hinton, known as the 'Godfather of AI' and Turing Award winner, resigned from Google to speak more freely about the dangers of artificial intelligence, expressing concerns about misinformation and the pace of AI development."

- title: "Voyager (GPT-4 in Minecraft)"
  date: "2023-05-25T00:00:00-07:00"
  tags: ["Research"]
  organizations: []
  models: ["GPT-4"]
  impact_areas: ["Research", "Robotics"]
  key_figures: []
  link: "https://arxiv.org/abs/2305.16291"
  description: "Researchers introduced Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that can explore, acquire skills, and make novel discoveries without human intervention using GPT-4."

- title: "Direct Preference Optimization"
  date: "2023-05-29T00:00:00-07:00"
  tags: ["Research"]
  organizations: ["Stanford University"]
  models: []
  impact_areas: ["Research", "Language Models"]
  key_figures: []
  link: "https://arxiv.org/abs/2305.18290"
  description: "Researchers introduced Direct Preference Optimization (DPO), a simpler and more efficient alternative to RLHF for aligning language models with human preferences, eliminating the need for reward modeling."

- title: "CAIS Extinction-Risk Letter"
  date: "2023-05-30T09:00:00-07:00"
  tags: ["Social", "Safety"]
  organizations: []
  models: []
  impact_areas: ["Public Perception", "Regulation"]
  key_figures: ["Geoffrey Hinton", "Yoshua Bengio", "Sam Altman", "Demis Hassabis"]
  link: "https://www.safe.ai/statement-on-ai-risk"
  description: "The Center for AI Safety released a statement signed by hundreds of AI researchers and industry leaders declaring that 'Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks.'"

- title: "NVIDIA Market Cap Hits $1T"
  date: "2023-05-30T16:00:00-04:00"
  tags: ["Corporate"]
  organizations: ["NVIDIA"]
  models: []
  impact_areas: ["Market Competition"]
  key_figures: ["Jensen Huang"]
  link: "https://www.reuters.com/technology/nvidia-hits-1-trillion-market-cap-2023-05-30/"
  description: "NVIDIA became the first chipmaker to reach a $1 trillion market capitalization, driven by surging demand for its GPUs used in AI applications and data centers powering the generative AI boom."

- title: "Claude 2"
  date: "2023-07-11T09:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude 2"]
  impact_areas: ["Language Models", "Enterprise AI"]
  key_figures: []
  link: "https://www.anthropic.com/index/claude-2"
  description: "Anthropic released Claude 2 with improved capabilities, a 100k token context window, and general public availability through claude.ai, marking a significant upgrade from the original Claude model."

- title: "xAI Founded"
  date: "2023-07-14T00:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["xAI"]
  models: []
  impact_areas: ["Market Competition"]
  key_figures: ["Elon Musk"]
  link: "https://x.ai/"
  description: "Elon Musk announced the formation of xAI, a new AI company with the stated goal to 'understand the true nature of the universe,' joining the competitive landscape alongside OpenAI, Google, and Anthropic."

- title: "LLaMA 2 Open-Sourced"
  date: "2023-07-18T09:00:00-07:00"
  tags: ["Model", "Product", "Economic"]
  organizations: ["Meta", "Microsoft"]
  models: ["LLaMA 2-7B", "LLaMA 2-13B", "LLaMA 2-70B"]
  impact_areas: ["Open Source", "Language Models", "Enterprise AI"]
  key_figures: ["Mark Zuckerberg"]
  link: "https://ai.meta.com/llama/"
  description: "Meta released LLaMA 2, a family of open-source large language models (7B, 13B, and 70B parameters) for commercial use, trained on 40% more data than LLaMA 1 and made available through partnerships with Microsoft Azure and AWS."

- title: "Automated Jailbreaks"
  date: "2023-07-27T00:00:00+00:00"
  tags: ["Research", "Safety"]
  organizations: []
  models: []
  impact_areas: ["Language Models"]
  key_figures: []
  link: "https://arxiv.org/abs/2307.08715"
  description: "July 27, 2023 – Introduced Jailbreaker, a methodology inspired by time‑based SQL injection to automatically reverse‑engineer and bypass defenses in chat models like ChatGPT, Bard, and Bing Chat" 

- title: "Mistral 7B"
  date: "2023-09-27T00:00:00+00:00"
  tags: ["Model"]
  organizations: ["Mistral AI"]
  models: ["Mistral 7B"]
  impact_areas: ["Language Models", "Open Source"]
  key_figures: []
  link: "https://mistral.ai/news/announcing-mistral-7b"
  description: "September 27, 2023 – Mistral 7B was released under Apache 2.0 license; a 7B‑parameter model outperformed open‑source LLaMA 2 13B on key benchmarks" 

- title: "Sparse‑autoencoder (SAEs)"
  date: "2023-10-05T00:00:00+00:00"
  tags: ["Research"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Language Models", "Research"]
  key_figures: []
  link: "https://arxiv.org/abs/2309.08600"
  description: "October 2023 – Anthropic published work on sparse autoencoders, demonstrating interpretable monosemantic features in model activations"

- title: "UK AI Safety Summit"
  date: "2023-11-01T00:00:00+00:00"
  tags: ["Policy", "Corporate"]
  organizations: []
  models: []
  impact_areas: ["Safety", "Regulation", "Public Perception"]
  key_figures: []
  link: "https://www.gov.uk/government/topical-events/ai-safety-summit-2023/about"
  description: "November 1–2, 2023 – Held at Bletchley Park, the first global AI Safety Summit produced the Bletchley Declaration, committing 28 nations to coordinated AI safety principles" 

- title: "GPT‑4 Turbo"
  date: "2023-11-06T00:00:00+00:00"
  tags: ["Product", "Model"]
  organizations: ["OpenAI"]
  models: ["GPT‑4 Turbo"]
  impact_areas: ["Language Models", "Enterprise AI"]
  key_figures: []
  link: "https://openai.com/index/new-models-and-developer-products-announced-at-devday/"
  description: "November 6, 2023 – At its first Dev Day, OpenAI debuted GPT‑4 Turbo with longer 128K context, significantly lower pricing, and faster performance for developers"

- title: "Sam Altman Board Drama"
  date: "2023-11-17T00:00:00+00:00"
  tags: ["Corporate", "Social"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Enterprise AI", "Public Perception"]
  key_figures: ["Sam Altman"]
  link: "https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI"
  description: "November 17, 2023 – OpenAI's board abruptly ousted CEO Sam Altman due to alleged miscommunication, prompting resignations and a staff-led reinstatement five days later" 

- title: "Rumors of 'Q*'"
  date: "2023-11-23T00:00:00+00:00"
  tags: ["Research", "Social"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Language Models", "Public Perception"]
  key_figures: []
  link: "https://arstechnica.com/ai/2023/12/the-real-research-behind-the-wild-rumors-about-openais-q-project/"
  description: "November 23, 2023 – Reports emerged about an OpenAI internal 'Q*' breakthrough in grade‑school math and AGI‐adjacent capabilities, later unverified but linked to Altman’s firing" 

- title: "Mamba Sequence"
  date: "2023-12-01T00:00:00+00:00"
  tags: ["Research"]
  organizations: []
  models: ["Mamba"]
  impact_areas: ["Research", "Language Models"]
  key_figures: []
  link: "https://arxiv.org/abs/2312.00752"
  description: "December 1, 2023 – Gu & Dao introduced Mamba, a linear-time sequence model using selective state spaces that rivals transformer quality at much lower compute"

- title: "Google Gemini"
  date: "2023-12-06T00:00:00+00:00"
  tags: ["Product", "Model"]
  organizations: ["Google"]
  models: ["Gemini"]
  impact_areas: ["Language Models", "Enterprise AI"]
  key_figures: []
  link: "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/"
  description: "December 6, 2023 – Google launched Gemini, a new AI model series, marking its entry into large multimodal and language models" 

- title: "Sora"
  date: "2024-02-15T09:00:00-08:00"
  tags: ["Model", "Product"]
  organizations: ["OpenAI"]
  models: ["Sora"]
  impact_areas: ["Multimodal AI", "Creator Economy"]
  key_figures: ["Sam Altman"]
  link: "https://openai.com/index/sora/"
  description: "On February 15 2024 OpenAI unveiled Sora, a text-to-video model that generates minute-long realistic clips from natural-language prompts."

- title: "Devin"
  date: "2024-03-12T10:00:00-07:00"
  tags: ["Product", "Model"]
  organizations: ["Cognition AI"]
  models: ["Devin"]
  impact_areas: ["Language Models", "Enterprise AI"]
  key_figures: ["Scott Wu"]
  link: "https://cognition.ai/blog/introducing-devin"
  description: "Cognition AI demonstrated Devin, billed as the first fully autonomous AI software engineer capable of completing SWE-bench tasks end-to-end." 

- title: "Safe Superintelligence"
  date: "2024-06-19T10:00:00-07:00"
  tags: ["Corporate", "Safety"]
  organizations: ["Safe Superintelligence Inc."]
  models: []
  impact_areas: ["Research", "Ethics"]
  key_figures: ["Ilya Sutskever"]
  link: "https://ssi.inc/"
  description: "Ilya Sutskever and colleagues launched Safe Superintelligence Inc., a new lab singularly focused on building provably safe super-intelligent systems." 

- title: "Claude 3.5 Sonnet"
  date: "2024-06-20T09:00:00-07:00"
  tags: ["Model"]
  organizations: ["Anthropic"]
  models: ["Claude 3.5 Sonnet"]
  impact_areas: ["Language Models", "Enterprise AI"]
  key_figures: ["Dario Amodei"]
  link: "https://www.anthropic.com/news/claude-3-5-sonnet"
  description: "Anthropic released Claude 3.5 Sonnet, its first 3.5-generation model, outperforming Claude 3 Opus while retaining mid-tier speed and cost." 

- title: "Cursor AI Goes Viral"
  date: "2024-08-23T12:00:00-07:00"
  tags: ["Product", "Social"]
  organizations: ["Anysphere"]
  models: []
  impact_areas: ["Creator Economy", "Enterprise AI"]
  key_figures: ["Michael Truell"]
  link: "https://www.instagram.com/tom.developer/reel/C_-iCOnvwDY/"
  description: "Social-media clips showcasing Cursor’s AI-assisted coding features went viral on August 23 2024, driving a surge of downloads and developer adoption."
- title: "Grok 2"
  date: "2024-08-24T09:00:00-07:00"
  tags: ["Model"]
  organizations: ["xAI"]
  models: ["Grok 2"]
  impact_areas: ["Language Models", "Market Competition"]
  key_figures: ["Elon Musk"]
  link: "https://x.ai/news/grok-2"
  description: "xAI unveiled Grok 2 and Grok 2 mini, claiming frontier-level chat, coding, and reasoning that outperformed Claude 3.5 Sonnet on LMSYS tests."

- title: "xAI Colossus Cluster"
  date: "2024-09-02T08:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["xAI"]
  models: []
  impact_areas: ["Hardware", "Market Competition"]
  key_figures: ["Elon Musk"]
  link: "https://x.com/elonmusk/status/1830650370336473253"
  description: "Elon Musk announced that xAI’s Colossus supercomputer—100 000 Nvidia H100 GPUs—came online just 122 days after ground-breaking, forming the world’s largest AI-training cluster." 

- title: "OpenAI o1-preview"
  date: "2024-09-12T09:00:00-07:00"
  tags: ["Model"]
  organizations: ["OpenAI"]
  models: ["o1"]
  impact_areas: ["Language Models"]
  key_figures: ["Sam Altman"]
  link: "https://openai.com/index/introducing-openai-o1-preview/"
  description: "OpenAI released o1-preview and o1-mini, reasoning-focused models that improve with extra inference-time ‘deliberation,’ inaugurating its new o-series." 

- title: "Mira Murati resigns OpenAI"
  date: "2024-09-25T17:05:00-07:00"
  tags: ["Corporate", "Social"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Market Competition", "Public Perception"]
  key_figures: ["Mira Murati"]
  link: "https://www.theguardian.com/technology/2024/sep/25/openai-cto-mira-murati-resigns"
  description: "On September 25 2024 CTO Mira Murati announced her departure from OpenAI after six years, citing a desire for ‘personal exploration.’" 

- title: "SB-1047 vetoed"
  date: "2024-09-29T12:00:00-07:00"
  tags: ["Policy", "Legal"]
  organizations: ["State of California"]
  models: []
  impact_areas: ["Regulation", "Safety"]
  key_figures: []
  link: "https://www.gov.ca.gov/wp-content/uploads/2024/09/SB-1047-Veto-Message.pdf"
  description: "Governor Gavin Newsom vetoed SB-1047, a bill that would have imposed safeguards and a new oversight board for frontier AI models in California."

- title: "Hinton & Hassabis Nobel Prizes"
  date: "2024-10-08T05:00:00-07:00"
  tags: ["Research", "Social"]
  organizations: ["Royal Swedish Academy of Sciences"]
  models: []
  impact_areas: ["Research", "Public Perception"]
  key_figures: ["Geoffrey Hinton", "Demis Hassabis"]
  link: "https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/"
  description: "Geoffrey Hinton shared the 2024 Nobel Prize in Physics and Demis Hassabis shared the Chemistry prize, honoring foundational AI contributions in neural networks and protein folding." 

- title: "“Machines of Loving Grace” essay series"
  date: "2024-10-11T09:00:00-07:00"
  tags: ["Social", "Research"]
  organizations: []
  models: []
  impact_areas: ["Public Perception", "Ethics"]
  key_figures: ["Dario Amodei"]
  link: "https://www.darioamodei.com/essay/machines-of-loving-grace"
  description: "Anthropic CEO Dario Amodei published the multi-part essay “Machines of Loving Grace,” outlining optimistic scenarios for AI-driven global progress." 

- title: "Situational Awareness essays"
  date: "2024-11-01T09:00:00-07:00"
  tags: ["Social", "Research", "Safety"]
  organizations: []
  models: []
  impact_areas: ["Safety", "Ethics", "Public Perception"]
  key_figures: ["Leopold Aschenbrenner"]
  link: "https://situational-awareness.ai/"
  description: "Ex-OpenAI researcher Leopold Aschenbrenner released his “Situational Awareness: The Decade Ahead” essay series forecasting rapid AGI progress and associated security risks." 

- title: "Gemini 2.0 announced"
  date: "2024-12-11T09:00:00-08:00"
  tags: ["Model"]
  organizations: ["Google DeepMind"]
  models: ["Gemini 2.0"]
  impact_areas: ["Language Models", "Multimodal AI"]
  key_figures: ["Demis Hassabis"]
  link: "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/"
  description: "Google DeepMind revealed Gemini 2.0 and the lightweight 2.0 Flash model, emphasizing agentic capabilities and native image-and-audio output." 

- title: "Veo 2"
  date: "2024-12-16T09:00:00-08:00"
  tags: ["Model", "Product"]
  organizations: ["Google DeepMind"]
  models: ["Veo 2"]
  impact_areas: ["Multimodal AI", "Creator Economy"]
  key_figures: []
  link: "https://blog.google/technology/google-labs/video-image-generation-update-december-2024/"
  description: "DeepMind introduced Veo 2, a 4K-capable text-to-video model now powering Google’s VideoFX tool and rivaling OpenAI’s Sora in realism."

- title: "OpenAI o3 Benchmarks"
  date: "2024-12-20T09:00:00-08:00"
  tags: ["Model", "Research"]
  organizations: ["OpenAI"]
  models: ["o3"]
  impact_areas: ["Language Models", "Research"]
  key_figures: ["Sam Altman"]
  link: "https://arcprize.org/blog/oai-o3-pub-breakthrough"
  description: "OpenAI’s o3 scored 87.5 % on the ARC-AGI benchmark in high-compute mode, a step-function gain over GPT-4o and prior public results." 

- title: "DeepSeek v3"
  date: "2024-12-26T09:00:00-08:00"
  tags: ["Model"]
  organizations: ["DeepSeek AI"]
  models: ["DeepSeek v3"]
  impact_areas: ["Language Models", "Open Source"]
  key_figures: []
  link: "https://arxiv.org/abs/2412.19437"
  description: "Chinese startup DeepSeek open-sourced DeepSeek v3, a 671 B-parameter MoE LLM that matches leading closed-source models while using only 37 B active parameters per token."

- title: "OpenAI Fires Leakers"
  date: "2024-04-11T12:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Enterprise AI"]
  key_figures: ["Leopold Aschenbrenner", "Pavel Izmailov"]
  link: "https://www.theinformation.com/articles/openai-researchers-including-ally-of-sutskever-fired-for-alleged-leaking"
  description: "OpenAI dismissed researchers Leopold Aschenbrenner and Pavel Izmailov for allegedly leaking internal information, underscoring heightened security and secrecy around the company’s AGI work."

- title: "LLaMA 3"
  date: "2024-04-18T09:00:00-07:00"
  tags: ["Model"]
  organizations: ["Meta"]
  models: ["LLaMA 3"]
  impact_areas: ["Language Models", "Open Source", "Market Competition"]
  key_figures: ["Mark Zuckerberg"]
  link: "https://ai.meta.com/blog/meta-llama-3/"
  description: "Meta open-sourced LLaMA 3, a family of 8 B and 70 B-parameter models, expanding access to high-performance language models and intensifying open-source competition in generative AI."

- title: "GPT-4o"
  date: "2024-05-13T09:00:00-07:00"
  tags: ["Model"]
  organizations: ["OpenAI"]
  models: ["GPT-4o"]
  impact_areas: ["Multimodal AI", "Language Models", "Enterprise AI"]
  key_figures: ["Sam Altman"]
  link: "https://openai.com/index/hello-gpt-4o/"
  description: "OpenAI unveiled GPT-4o, an ‘omni-model’ that unifies text, vision and audio reasoning in real time while halving API costs, signaling a major leap toward seamless multimodal AI services."

- title: "Ilya Sutskever Resigns"
  date: "2024-05-14T17:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Enterprise AI", "Safety"]
  key_figures: ["Ilya Sutskever", "Sam Altman"]
  link: "https://www.reuters.com/technology/openai-co-founder-ilya-sutskever-departs-2024-05-14/"
  description: "Co-founder and chief scientist Ilya Sutskever left OpenAI to pursue a new project, ending a decade-long tenure that shaped breakthrough models and OpenAI’s safety agenda."

- title: "EU AI Act Final Passage"
  date: "2024-05-21T15:00:00+02:00"
  tags: ["Policy"]
  organizations: ["European Union"]
  models: []
  impact_areas: ["Regulation", "Ethics"]
  key_figures: ["Ursula von der Leyen"]
  link: "https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law"
  description: "The European Parliament gave final approval to the landmark AI Act, establishing the world’s first comprehensive risk-tiered regulatory framework for artificial intelligence systems."

- title: "Situational Awareness Essays"
  date: "2024-06-04T09:00:00-07:00"
  tags: ["Research", "Safety"]
  organizations: []
  models: []
  impact_areas: ["Research", "Public Perception", "Safety"]
  key_figures: ["Leopold Aschenbrenner"]
  link: "https://situational-awareness.ai/"
  description: "Leopold Aschenbrenner released the multi-part essay series “Situational Awareness: The Decade Ahead,” arguing that AGI could arrive by 2027 and urging massive U.S. investment and tighter security measures."

- title: "Claude Computer-Use"
  date: "2024-10-22T09:00:00-07:00"
  tags: ["Model", "Product"]
  organizations: ["Anthropic"]
  models: ["Claude 3.5 Haiku"]
  impact_areas: ["Language Models", "Multimodal AI", "Enterprise AI"]
  key_figures: ["Dario Amodei"]
  link: "https://www.anthropic.com/news/3-5-models-and-computer-use"
  description: "Anthropic rolled out Claude 3.5 Haiku and a new ‘computer-use’ tool that lets Claude autonomously navigate software, expanding the model family’s speed tier and practical task automation capabilities."

- title: "Trump Wins 2024 Election"
  date: "2024-11-06T00:00:00-05:00"
  tags: ["Policy", "Social"]
  organizations: ["U.S. Government"]
  models: []
  impact_areas: ["Regulation", "Public Perception", "Market Competition"]
  key_figures: ["Donald Trump", "Elon Musk"]
  link: "https://www.reuters.com/world/us/trump-vs-harris-us-voters-head-polls-turbulent-campaign-concludes-2024-11-05/"
  description: "Donald Trump was elected U.S. president after a campaign bolstered by Elon Musk’s public backing, setting the stage for a pro-industry stance on AI and looser crypto regulation."

- title: "Comission Urges AI Manhattan Project"
  date: "2024-11-19T10:00:00-05:00"
  tags: ["Policy", "Corporate", "Social"]
  organizations: []
  models: []
  impact_areas: ["Regulation", "Market Competition", "Research"]
  key_figures: []
  link: "https://www.reuters.com/technology/artificial-intelligence/us-government-commission-pushes-manhattan-project-style-ai-initiative-2024-11-19/"
  description: "The U.S.–China Economic and Security Review Commission recommended a federally led, Manhattan Project–scale initiative to accelerate AGI development and secure U.S. technological supremacy over China."

- title: "David Sacks AI & Crypto Czar"
  date: "2024-12-04T09:00:00-05:00"
  tags: ["Policy"]
  organizations: ["U.S. Government"]
  models: []
  impact_areas: ["Regulation", "Enterprise AI"]
  key_figures: ["David Sacks"]
  link: "https://www.reuters.com/world/us/trump-appoints-former-paypal-coo-david-sacks-ai-crypto-czar-2024-12-06/"
  description: "President-elect Trump appointed venture capitalist David Sacks as White House “AI & Crypto Czar,” tasking him with steering national AI strategy and cryptocurrency policy in the incoming administration."

- title: "Anthropic Series F"
  date: "2025-09-02T12:00:00-07:00"
  tags: ["Economic"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Market Competition", "Enterprise AI"]
  key_figures: []
  link: "https://ppc.land/anthropic-completes-13-billion-series-f-funding-at-183-billion-valuation/"
  description: "Anthropic completed record-breaking $13 billion Series F funding at $183 billion post-money valuation, nearly tripling from March 2025's $61.5B, making it fourth most valuable startup globally as revenue grew from $1B to $5B in eight months."

- title: "Apertus OS Model"
  date: "2025-09-02T14:00:00+01:00"
  tags: ["Model", "Open Source"]
  organizations: ["EPFL", "ETH Zurich"]
  models: ["Apertus"]
  impact_areas: ["Open Source", "Language Models", "Regulation"]
  key_figures: []
  link: "https://theaitrack.com/switzerland-apertus-open-ai-model-launch/"
  description: "Switzerland launched Apertus, a fully open-source national LLM trained on 15T tokens across 1,000+ languages (40% non-English), with complete transparency including open weights, training data, and documentation, compliant with EU AI Act as public digital infrastructure."

- title: "Anthropic Copyright Settlement"
  date: "2025-09-05T09:00:00-07:00"
  tags: ["Legal"]
  organizations: ["Anthropic"]
  models: []
  impact_areas: ["Regulation", "Ethics"]
  key_figures: []
  link: "https://theaitrack.com/anthropic-will-pay-1-5b-ai-copyright-settlement/"
  description: "Anthropic agreed to landmark $1.5 billion settlement resolving class-action lawsuit over training Claude on pirated copies of ~500,000 books from LibGen and Pirate Library Mirror, with authors receiving ~$3,000 per infringed book and Anthropic destroying pirated dataset."

- title: "ASML-Mistral Partnership"
  date: "2025-09-07T10:00:00+02:00"
  tags: ["Economic", "Partnership"]
  organizations: ["ASML", "Mistral AI"]
  models: []
  impact_areas: ["Hardware", "Market Competition"]
  key_figures: []
  link: "https://techcrunch.com/2025/09/09/what-is-mistral-ai-everything-to-know-about-the-openai-competitor/"
  description: "Dutch chip-equipment giant ASML led €1.7 billion funding round in Mistral AI with €1.3 billion investment, valuing the European AI startup at €10 billion and establishing strategic partnership to integrate AI capabilities into ASML's lithography tools."

- title: "OpenAI-Anthropic Evaluation Initiative"
  date: "2025-09-06T13:00:00-07:00"
  tags: ["Safety", "Research"]
  organizations: ["OpenAI", "Anthropic"]
  models: []
  impact_areas: ["Ethics", "Research"]
  key_figures: []
  link: "https://theaitrack.com/openai-and-anthropic-joint-safety-evaluation/"
  description: "OpenAI and Anthropic opened APIs for cross-laboratory safety audits, conducting joint evaluations on sycophancy, misuse cooperation, jailbreak resistance, and refusal-helpfulness trade-offs to advance AI safety research and transparency."

- title: "Grok 2.5 Open Source"
  date: "2025-09-09T16:00:00-07:00"
  tags: ["Model", "Open Source"]
  organizations: ["xAI"]
  models: ["Grok 2.5"]
  impact_areas: ["Open Source", "Language Models"]
  key_figures: []
  link: "https://theaitrack.com/xai-open-sources-grok-2-5/"
  description: "xAI open-sourced Grok 2.5 (last year's best model) and pledged Grok 3 release in six months, praised by Sebastian Rashka for releasing full production models rather than lite versions, highlighting transparency and enterprise benefits."

- title: "Greece OpenAI Partnership"
  date: "2025-09-05T15:00:00+03:00"
  tags: ["Policy", "International"]
  organizations: ["OpenAI", "Government of Greece"]
  models: ["ChatGPT"]
  impact_areas: []
  key_figures: []
  link: "https://www.reuters.com/technology/greece-openai-national-partnership-2025-09-05"
  description: "Greek Prime Minister Kyriakos Mitsotakis personally attended the signing of a memorandum of understanding with OpenAI, establishing a 'national AI partnership' to boost innovation in Greece's economy. Greek tech startups will receive credits and early access to OpenAI's APIs, with the aim of boosting innovation in healthcare, climate, education, and public services. The model of a 'national AI partnership' could be copied by other midsized countries."

- title: "Anthropic NYT Settlement"
  date: "2025-09-05T11:00:00-07:00"
  tags: ["Legal", "Media"]
  organizations: ["Anthropic", "The New York Times"]
  models: []
  impact_areas: ["Copyright"]
  key_figures: []
  link: "https://www.nytimes.com/2025/09/05/business/anthropic-settlement-copyright"
  description: "Anthropic reached a confidential settlement with The New York Times over allegations that it used copyrighted articles to train its AI models, marking one of the first major copyright resolutions between a news outlet and a leading AI firm. The case stirred debate over fair use and media rights in generative AI, with terms of the agreement not disclosed publicly."

- title: "Meta-Midjourney Partnership"
  date: "2025-09-10T11:00:00-07:00"
  tags: ["Partnership"]
  organizations: ["Meta", "Midjourney"]
  models: []
  impact_areas: ["Creator Economy", "Multimodal AI"]
  key_figures: []
  link: "https://theaitrack.com/meta-partners-with-midjourney/"
  description: "Meta formed technology licensing partnership with Midjourney to integrate advanced image and video generation capabilities into Meta's AI products, expanding creative AI portfolio while pursuing superintelligence ambitions."

- title: "OpenAI Acquires Statsig"
  date: "2025-09-02T12:00:00-07:00"
  tags: ["Corporate"]
  organizations: ["OpenAI"]
  models: []
  impact_areas: ["Product Development", "Enterprise AI"]
  key_figures: ["Vijaye Raji", "Fidji Simo", "Sam Altman"]
  link: "https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig"
  description: "OpenAI acquired product testing startup Statsig for $1.1 billion in an all-stock deal, one of its largest acquisitions to date. Statsig CEO Vijaye Raji was named CTO of Applications at OpenAI, reporting to Fidji Simo. The acquisition brings Statsig's A/B testing, feature flagging, and real-time decisioning platform in-house to accelerate product development across OpenAI's Applications organization."